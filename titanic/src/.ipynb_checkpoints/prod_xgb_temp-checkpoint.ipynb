{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52850930-9539-4beb-81cc-66476b59a4f6",
   "metadata": {},
   "source": [
    "### This is Prod script, building and deploying simple XGB model for Titanic\n",
    "\n",
    "Since it uses only RF and XGBoost, it is simpler than dev script for this project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bfb71f-bb6b-411f-a128-5c1e61b6487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_run_id = 1\n",
    "# notebook_run_id is a digit, creating and deploying a new model every time this notebook is run. increment it by 1.\n",
    "project_name = 'My First Project'\n",
    "project_id = 'quantum-keep-360100'\n",
    "regionn = 'us-central1'\n",
    "\n",
    "ml_project_name = 'titanic'\n",
    "model_name = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a220d1-04c2-42fb-8bca-d564de61cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load libraries #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, warnings, optuna, pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from google.cloud import bigquery, storage\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load custom pre-processing functions:\n",
    "\n",
    "def fillna_mp_i1(df_train, df_test, df_pred, num_features, cat_features, num_fill='median', cat_fill='mode'):\n",
    "    \"\"\"This function speeds up filling missing values for 3 main datasets using different imputation methods.\n",
    "    Later may replace it with some subclass.\n",
    "    Example: fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\"\"\"\n",
    "    # set df_pred to None if it does not exist\n",
    "    if not ((cat_fill=='mode') and (num_fill=='median')):\n",
    "        print ('Imputation method not Implemented yet!')\n",
    "        return None\n",
    "    \n",
    "    df_train[num_features] = df_train[num_features].fillna(value=df_train[num_features].median())\n",
    "    df_test[num_features] = df_test[num_features].fillna(value=df_train[num_features].median())\n",
    "    df_train[cat_features] = df_train[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n",
    "    df_test[cat_features] = df_test[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n",
    "    if (df_pred is not None):\n",
    "        df_pred[num_features] = df_pred[num_features].fillna(value=df_train[num_features].median())\n",
    "        df_pred[cat_features] = df_pred[cat_features].fillna(value=df_train[cat_features].mode().iloc[0])\n",
    "    df_train[num_features+cat_features].count\n",
    "    \n",
    "    all_good = (\n",
    "    (np.prod(df_train[num_features+cat_features].shape)==df_train[num_features+cat_features].count().sum()) and \n",
    "    (np.prod(df_test[num_features+cat_features].shape) == df_test[num_features+cat_features].count().sum()) and \n",
    "    (np.prod(df_pred[num_features+cat_features].shape) == df_pred[num_features+cat_features].count().sum()))\n",
    "    if (all_good):\n",
    "        print('Missing values imputed successfully')\n",
    "    else:\n",
    "        print('There are still some missing values...')\n",
    "    \n",
    "def add_misDummy_mp_i1(df_train, df_test, df_pred, features):\n",
    "    \"\"\"This function creates new dummy columns for missing features.\n",
    "    Example: add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\"\"\"\n",
    "    # set df_pred to None if it does not exist\n",
    "    for feature_name in features:\n",
    "        misColName = 'mis'+feature_name\n",
    "        df_train.loc[df_train[feature_name].isnull(), misColName]=1\n",
    "        df_train.loc[df_train[feature_name].notnull(), misColName]=0\n",
    "        df_test.loc[df_test[feature_name].isnull(), misColName]=1\n",
    "        df_test.loc[df_test[feature_name].notnull(), misColName]=0\n",
    "        if (df_pred is not None):\n",
    "            df_pred.loc[df_pred[feature_name].isnull(), misColName]=1\n",
    "            df_pred.loc[df_pred[feature_name].notnull(), misColName]=0\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e582e58-ad0c-4982-8c0a-84a4afc9579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 8) (418, 7)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data #\n",
    "\n",
    "time0 = time.time()\n",
    "\n",
    "os.chdir('/home/jupyter/projects_data/titanic')\n",
    "df = pd.read_csv('train.csv') \n",
    "\n",
    "df.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n",
    "pred = pd.read_csv('test.csv')\n",
    "pred.drop(columns=['Name', 'Ticket', 'Cabin', 'PassengerId'],inplace=True)\n",
    "\n",
    "print(df.shape, pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865174ee-c143-4bcd-9a33-848a88bd2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical features:  ['Sex', 'Embarked'] numerical features:  ['Parch', 'Age2', 'SibSp', 'Age', 'Pclass', 'Fare']\n",
      "(712, 8) (179, 8) (712, 1) (418, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 42 to 122\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    712 non-null    int64  \n",
      " 1   Sex       712 non-null    object \n",
      " 2   Age       570 non-null    float64\n",
      " 3   SibSp     712 non-null    int64  \n",
      " 4   Parch     712 non-null    int64  \n",
      " 5   Fare      712 non-null    float64\n",
      " 6   Embarked  710 non-null    object \n",
      " 7   Age2      570 non-null    float64\n",
      "dtypes: float64(3), int64(3), object(2)\n",
      "memory usage: 50.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# 2. EDA, adding features #\n",
    "\n",
    "df['Age2'] = df['Age']**2\n",
    "pred['Age2'] = pred['Age']**2\n",
    "\n",
    "# 3. Train-test split #\n",
    "\n",
    "train_y = df[['Survived']]\n",
    "train_x = df.drop(columns = ['Survived'])\n",
    "X_pred = pred.copy()\n",
    "\n",
    "cat_cols = ['Sex', 'Embarked']\n",
    "num_cols = list(set(train_x.columns)-set(cat_cols))\n",
    "\n",
    "print('categorical features: ', cat_cols, 'numerical features: ', num_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.2, random_state=4)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, X_pred.shape)\n",
    "\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd6796a-a6df-4c60-a9fb-7fedcd5b6cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values imputed successfully\n"
     ]
    }
   ],
   "source": [
    "# 4. Misisng values #\n",
    "\n",
    "add_misDummy_mp_i1(X_train, X_test, X_pred, ['Age'])\n",
    "\n",
    "fillna_mp_i1(X_train, X_test, X_pred, num_cols, cat_cols)\n",
    "\n",
    "cat_cols.extend(['misAge'])\n",
    "\n",
    "feature_transformer = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(sparse = False, handle_unknown=\"ignore\", drop='if_binary'), cat_cols)],\n",
    "        remainder = \"passthrough\"\n",
    "    )\n",
    "\n",
    "X_train = pd.DataFrame(feature_transformer.fit_transform(X_train), columns=feature_transformer.get_feature_names_out())\n",
    "X_test = pd.DataFrame(feature_transformer.transform(X_test), columns=feature_transformer.get_feature_names_out())\n",
    "X_pred = pd.DataFrame(feature_transformer.transform(X_pred), columns=feature_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14974503-08fd-460f-9ec8-152f5b390150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF  {'max_depth': 6, 'max_features': 5, 'n_estimators': 200} \n",
      " 0.8721910112359551 0.8532986970146792 14.417773723602295\n",
      "XGB  {'colsample_bytree': 0.6, 'eta': 0.01, 'max_depth': 4, 'n_estimators': 250, 'subsample': 0.7} \n",
      " 0.8581460674157303 0.8386194952993569 38.61670207977295\n",
      "Out of Sample:\n",
      "RF  0.8324022346368715 0.7871848739495798\n",
      "XGB  0.8212290502793296 0.7829131652661064\n",
      "Total time  53.256232023239136\n",
      "Total time for training part:  53.2563054561615\n"
     ]
    }
   ],
   "source": [
    "# 6. Fit models #\n",
    "\n",
    "time1 = time.time()\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {'n_estimators':[100, 200], \n",
    "              'max_depth':[3, 4, 5, 6, 7], \n",
    "              'max_features':[4, 5, 6]}\n",
    "rfm = GridSearchCV(rf, param_grid, cv=2)\n",
    "rfm.fit(X_train, y_train)\n",
    "print('RF ', \n",
    "      rfm.best_params_, \n",
    "      '\\n',\n",
    "      accuracy_score(y_train, rfm.predict(X_train)), \n",
    "      roc_auc_score(y_train, rfm.predict(X_train)), time.time()-time1)\n",
    "\n",
    "time1 = time.time()\n",
    "xgb = XGBClassifier()\n",
    "# use 'gpu_hist' for more than 10,000 examples.\n",
    "param_grid = {'n_estimators':[150, 250], \n",
    "              'max_depth':[2, 3, 4], \n",
    "              'eta':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06], \n",
    "              'subsample':[0.7],\n",
    "              'colsample_bytree':[0.6]}\n",
    "xgbm = GridSearchCV(xgb, param_grid, cv=2)\n",
    "xgbm.fit(X_train, y_train)\n",
    "print('XGB ', \n",
    "      xgbm.best_params_, \n",
    "      '\\n',\n",
    "      accuracy_score(y_train, xgbm.predict(X_train)), \n",
    "      roc_auc_score(y_train, xgbm.predict(X_train)), \n",
    "      time.time()-time1)\n",
    "\n",
    "\n",
    "# 7. model evaluation #\n",
    "\n",
    "print('Out of Sample:')\n",
    "print('RF ', \n",
    "      accuracy_score(y_test, rfm.predict(X_test)), \n",
    "      roc_auc_score(y_test, rfm.predict(X_test)))\n",
    "print('XGB ', \n",
    "      accuracy_score(y_test, xgbm.predict(X_test)), \n",
    "      roc_auc_score(y_test, xgbm.predict(X_test)))\n",
    "print('Total time ', time.time()-time0)\n",
    "\n",
    "print('Total time for training part: ', time.time() - time0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd93e71-29bb-4d1a-8c21-2f57d89093a5",
   "metadata": {},
   "source": [
    "The results are somewhat surprising. I have played for more than 1 hours with hyprparmeters and RF still usually beats XGB. \n",
    "If I do hyperparemter tuning rigorously (e.g., Optuna), xgb will probably beat RF eventually. But do not want to waste more time on this, given that thi is Prod script. So I use RF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65b8e3-3eae-41fb-81c0-f1c9989fd181",
   "metadata": {},
   "source": [
    "#### RF Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e446569-1a1f-48b7-81da-d33861fc74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_time_start = time.time()\n",
    "\n",
    "os.chdir('/home/jupyter/projects_gcp_cpu')\n",
    "\n",
    "model_path = os.getcwd()+'/titanic/artifacts/model_rf/'\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "artifact_filename = 'model.pkl'\n",
    "with open(model_path+artifact_filename, 'wb') as model_file:\n",
    "  pickle.dump(rfm, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a71550d-31e1-4c89-80e5-fddc2a7c78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model artifact to Cloud Storage\n",
    "# Change the model directory to your GCS bucket URI\n",
    "model_bucket = 'gs://pmykola-projectsgcp-artifacts/titanic-rf'\n",
    "storage_path = os.path.join(model_bucket, artifact_filename)\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client(project=project_id))\n",
    "# previously it was 'project_id'\n",
    "blob.upload_from_filename(model_path+artifact_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da757d60-acf5-47e2-be43-031b52cbbcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/234443118908/locations/us-central1/models/2948797826718498816/operations/4305759346224005120\n",
      "Model created. Resource name: projects/234443118908/locations/us-central1/models/2948797826718498816@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/234443118908/locations/us-central1/models/2948797826718498816@1')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Use this line so we do not need to explicitly specify the project number and region whenever we use AI Platform (Vertex AI) services\n",
    "aiplatform.init(project=project_id, location=regionn)\n",
    "\n",
    "# Importing model artifacts\n",
    "model = aiplatform.Model.upload(display_name = ml_project_name+model_name+str(notebook_run_id),\n",
    "    description = ml_project_name+model_name+str(notebook_run_id),\n",
    "    artifact_uri = model_bucket,\n",
    "    serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21d0307b-5ed9-4969-8b32-c6cc0de2d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/234443118908/locations/us-central1/endpoints/15626259253952512/operations/5449673651576111104\n",
      "Endpoint created. Resource name: projects/234443118908/locations/us-central1/endpoints/15626259253952512\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/234443118908/locations/us-central1/endpoints/15626259253952512')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name = ml_project_name+model_name+str(notebook_run_id), \n",
    "                                      project = project_id, \n",
    "                                      location = regionn)\n",
    "endpoint_id = endpoint.resource_name[-19:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "444a9410-15e8-47a7-b863-88813e5cc0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/234443118908/locations/us-central1/endpoints/15626259253952512\n",
      "Deploy Endpoint model backing LRO: projects/234443118908/locations/us-central1/endpoints/15626259253952512/operations/6933609728794689536\n",
      "Endpoint model deployed. Resource name: projects/234443118908/locations/us-central1/endpoints/15626259253952512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f6f033f2250> \n",
       "resource name: projects/234443118908/locations/us-central1/endpoints/15626259253952512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even RF is slow to deploy...\n",
    "# at least 8 min\n",
    "# have to experiment with more powerful machines, maybe they will work faster\n",
    "model.deploy(endpoint = endpoint,\n",
    "             machine_type = 'n1-standard-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdd15228-d3af-4508-8943-f7a0b45398d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[0.0], deployed_model_id='5752420536151965696', model_version_id='1', model_resource_name='projects/234443118908/locations/us-central1/models/2948797826718498816', explanations=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'s/15626259253952512'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(endpoint.predict(instances=[[1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 28.5, 0.0, 0.0, 7.8958, 812.25]]))\n",
    "endpoint_id = endpoint.resource_name[-19:]\n",
    "display(endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1781a48e-310e-41b9-95bf-6ab06c4091ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ai.endpoints.predict) HTTPError 404\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "payload = {'instances': [[1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 28.5, 0.0, 0.0, 7.8958, 812.25], \n",
    "                         [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 34.0, 0.0, 0.0, 7.8958, 812.25]]}\n",
    "\n",
    "# Parse JSON\n",
    "with open('request.json', 'w') as outfile:\n",
    "    json.dump(payload, outfile)\n",
    "\n",
    "!gcloud ai endpoints predict $endpoint_id \\\n",
    "  --region=$regionn \\\n",
    "  --json-request=request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbb82f-27f0-48f8-8ebf-bc715952e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model deployment time: ', time.time() - deployment_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b444477-3cae-41cf-b236-035a2a86be2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cffc07-7847-4f11-9976-b5c8efe5f968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b830c40-d086-4c29-ac57-ed50abae9f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 28.5, 0.0, 0.0, 7.8958, 812.25]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c08543b-9095-44f2-be28-9a4f7333e42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__Sex_male</th>\n",
       "      <th>cat__Embarked_C</th>\n",
       "      <th>cat__Embarked_Q</th>\n",
       "      <th>cat__Embarked_S</th>\n",
       "      <th>cat__misAge_1.0</th>\n",
       "      <th>remainder__Pclass</th>\n",
       "      <th>remainder__Age</th>\n",
       "      <th>remainder__SibSp</th>\n",
       "      <th>remainder__Parch</th>\n",
       "      <th>remainder__Fare</th>\n",
       "      <th>remainder__Age2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>3600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5500</td>\n",
       "      <td>1296.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>1600.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>812.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>961.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>3136.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1056.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cat__Sex_male  cat__Embarked_C  cat__Embarked_Q  cat__Embarked_S  \\\n",
       "0              1.0              1.0              0.0              0.0   \n",
       "1              1.0              0.0              0.0              1.0   \n",
       "2              1.0              0.0              0.0              1.0   \n",
       "3              0.0              0.0              0.0              1.0   \n",
       "4              1.0              0.0              0.0              1.0   \n",
       "..             ...              ...              ...              ...   \n",
       "707            1.0              0.0              0.0              1.0   \n",
       "708            1.0              1.0              0.0              0.0   \n",
       "709            1.0              0.0              0.0              1.0   \n",
       "710            1.0              1.0              0.0              0.0   \n",
       "711            1.0              1.0              0.0              0.0   \n",
       "\n",
       "     cat__misAge_1.0  remainder__Pclass  remainder__Age  remainder__SibSp  \\\n",
       "0                1.0                3.0            28.5               0.0   \n",
       "1                0.0                2.0            60.0               1.0   \n",
       "2                0.0                3.0            36.0               1.0   \n",
       "3                1.0                3.0            28.5               3.0   \n",
       "4                1.0                1.0            28.5               0.0   \n",
       "..               ...                ...             ...               ...   \n",
       "707              0.0                3.0            40.0               1.0   \n",
       "708              1.0                3.0            28.5               1.0   \n",
       "709              0.0                2.0            31.0               0.0   \n",
       "710              0.0                1.0            56.0               0.0   \n",
       "711              0.0                2.0            32.5               1.0   \n",
       "\n",
       "     remainder__Parch  remainder__Fare  remainder__Age2  \n",
       "0                 0.0           7.8958           812.25  \n",
       "1                 1.0          39.0000          3600.00  \n",
       "2                 0.0          15.5500          1296.00  \n",
       "3                 1.0          25.4667           812.25  \n",
       "4                 0.0          30.0000           812.25  \n",
       "..                ...              ...              ...  \n",
       "707               4.0          27.9000          1600.00  \n",
       "708               1.0          15.2458           812.25  \n",
       "709               0.0          10.5000           961.00  \n",
       "710               0.0          30.6958          3136.00  \n",
       "711               0.0          30.0708          1056.25  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57a88d-f4d8-4423-9b33-140697754497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fd509-6621-4560-97e6-21d51fa9b1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
